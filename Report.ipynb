{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Section 1 - Introductions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font size=\"6\">**1.1 Background**</font>\n",
    "\n",
    "<u>_What is deepfake?_</u>\n",
    "\n",
    "When searching on the Internet, it is no surprise that fake images, manipulated videos and audios exist all over the Internet thanks to the advancement of the Internet and different editing software. In recent years,‘Deepfake’ technology has further put the authenticity and reliability of the media posted on the Internet in question. The term deepfake can be separated into two daily words: ‘deep’ and ‘fake’. For ‘deep’, it refers to the technique used, which is known as deep learning and for ‘fake’, it can be describing the creation of synthetic and falsified content. Deepfake can exist in various forms, one common usage is face-swapping in video and digital content, lip-syncing and face synthesis content are also common.\n",
    "\n",
    "\n",
    "<u>_How deepfakes are made?_</u>\n",
    "\n",
    "Deepfake has gone easier in these years with the help of powerful tools and algorithms. For the best deepfake performance, creating the models with **autoencoders** or the **generative adversarial network (GAN)** can be the most common deepfake creation algorithm. Using autoencoders, the common encoder can find and learn the similarity between two sets of face images. In the figure, a face image of face B is reconstructed with the mouth shape of face A (as the original mouth shape is upside-down, and now the mouth shape follows face A with a normal heart shape). In short, autoencoder combines the facial features of two target individuals to create a new ‘deepfake’ image.\n",
    "\n",
    "<img src=\"p/autoencoders.jpg\" width=400 height=300>\n",
    "\n",
    "For higher-level deepfake content creation, the generative adversarial network (GAN) can be adopted. During training, a combative process can be observed. In the GAN architecture, there are generator and discriminator. The generator uses random noise to produce images that are similar to the training data, meanwhile, the discriminator estimates the probability of images coming from real data samples, and also grades the generator for their resembling performance. Therefore, the generator can create high-quality deepfake images based on discriminator feedback, and at the same time it can be a useful tool to detect deepfake content.\n",
    "\n",
    "<img src=\"p/gan.png\" width=600 height=350>\n",
    "\n",
    "<u>_Deepfake effects_</u>\n",
    "\n",
    "The breakout of ‘Deepfake’ has made a lot of noise in the media space. Although it can create interesting memes for entertainment, deepfake also creates troubles in different aspects. It has been used to commit crimes from fraud to sexual harassment. Criminals use deepfake images and audio to impersonate a CEO to make violent threats. An AI firm also found that 96% of deepfake videos are pornographic by mapping the faces of female celebrities to porn stars. It also creates political and social issues, could you imagine the effect brought by impersonating the footage or the speech of presidents? Therefore, the effects of deepfake can be far beyond our imagination.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font size=\"6\">**1.2 Literature Review**</font>\n",
    "\n",
    "We can see that many adverse effects can be brought to our society with deepfake creation. Therefore, it is important to detect deepfake content by using high-level technology and algorithms. Throughout the deepfake detection history, there is a lot of research work conducted using different techniques.\n",
    "\n",
    "<u>_Frequency domain analysis with classifiers_</u>\n",
    "\n",
    "For example, traditional classifiers such as SVM can be used to classify deepfake content. **Agarwal** (2021) and **Durall** (2020) conducted deepfake image detection in the following approach. The input image is processed under Fourier transform for frequency domain analysis and to indicate how signal energy can be distributed over a range of frequency. After data preprocessing, the 1d power spectrum of the input images can be observed. The difference between fake and real images is about the curve of the spectrum. We can see it from the figure. If it is fake, the curve tends to be flatter when the frequency increases. Then, the classifiers can be applied to the datasets such as SVM and logistic regression. Agarwal has experimented on 3 datasets with these classifiers and all of them have a good performance. However, the potential issue can be it is hard to identify low resolution content as available frequency spectrum is much smaller. Also, the data preprocessing can be very complicated as there are other preprocessing steps other than the method of using Fourier transform just mentioned.\n",
    "<br/>\n",
    "<img src=\"p/table.png\" width=600 height=400><br/>\n",
    "<img src=\"p/curve.png\" width=300 height=300><img src=\"p/result_classifier.png\" width=300 height=300><br/>\n",
    "\n",
    "\n",
    "\n",
    "<u>_Convolution Neural Network_</u>\n",
    "\n",
    "Another deepfake detection technique could be using **Convolution Neural Network (CNN)**. The first CNN architecture can date back to **Fukushima’s neocognitron**, which consists of components such as feature extraction (S-cells), pooling layers (C-cells), and using convolution in a neural network (Fukushima, 1980), followed by some of the famous CNN such as **LeCun’s LeNet-5** in 1989, **Hinton’s AlexNet** in 2012 and **VGG-16** in 2014.\n",
    "\n",
    "In general, a CNN has three layers, which are convolution layer, pooling layer and fully connected layer. For convolution layer, the convolution process occurs using a matrix that iterated over the input data. An activation function will calculate the result of the filter and the area of the image and is stored in the feature matrix. For pooling layer, it is used for downsampling and dimensionality reduction to reduce computation power. And lastly for fully connected layer, the input matrix is flattened into column vector and it is passed through hidden layers of the neural networks using the sigmoid or softmax function. Over a series of epochs, the layer can finally classify the images.\n",
    "\n",
    "<img src=\"p/cnn.png\" width=800>\n",
    "\n",
    "**Lee (2021)** has conducted the deepfake detection based on different CNN. For example, multitask cascaded convolutional networks for face extraction, InceptionV3 and MobileNet (pretrained CNN models) are also utilized for training face patches to discriminate between actual and fake faces.\n",
    "\n",
    "\n",
    "<img src=\"p/lee.png\" width=500 height=300>\n",
    "\n",
    "\n",
    "<u>_ResNet_</u>\n",
    "\n",
    "There are different variations of algorithms based on CNN. **KaiMing He (2015)** invented the residual network to solve the gradient vanishing and degradation issues in other neural networks. The main component of the ResNet is the residual block. When the residual block receives input x and learns the features as H(x). Residual exists in the form of F(x) = H(x) - x, which implies that features learning can be interpreted as F(x) + x, which is the combination of input and residual. With the identity mapping feature that connects a layer to further layers and skip some middle layers, it achieves the feature learning in the form of F(x) + x, lowers the complexity of learning, and reduces the problem of gradient vanishing as it will not affect the model’s performance.\n",
    "\n",
    "<img src=\"p/resnet.png\" width=300 height=200>\n",
    "\n",
    "**Gupta (2021)** and **Hoq (2021)**  has performed deepfake image detection using different pre-trained model which are all based on CNN architecture. For example, they both apply ResNet50, which consists of 48 convolution layers, 1 max pooling layer and 1 average pooling layer. From Gupta experiment, there is a total of 51,036 images and are divided into two categories: real and fake in the ratio of 4 to 6 and 4 types of networks are applied. For testing accuracy, Xception scores the highest but with the higher loss and ResNet-50 ranks the second. However, their inference time will be the longest for training the model to 10 epochs.\n",
    "\n",
    "<img src=\"p/resnettable.png\" width=800 height=100>\n",
    "\n",
    "From Hoq experiment, ResNet50 also have good performance with high accuracy, precision and recall.\n",
    "\n",
    "<img src=\"p/resnet_table2.png\" width=800 height=100>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (994852124.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"C:\\Users\\wuchu\\AppData\\Local\\Temp\\ipykernel_9772\\994852124.py\"\u001B[1;36m, line \u001B[1;32m1\u001B[0m\n\u001B[1;33m    <font size=\"6\">**1.2 Literature Review**</font>\u001B[0m\n\u001B[1;37m    ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Section 2 - Experiments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Training Models and Saving Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Install and import the required packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1475430180.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"C:\\Users\\wuchu\\AppData\\Local\\Temp\\ipykernel_17740\\1475430180.py\"\u001B[1;36m, line \u001B[1;32m1\u001B[0m\n\u001B[1;33m    Installing required packages:\u001B[0m\n\u001B[1;37m               ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pip tensorflow-determinism\n",
    "# pip install numpy\n",
    "# pip install opencv-python\n",
    "# pip install scikit-learn\n",
    "# pip install keras\n",
    "# pip install tensorflow\n",
    "# pip install matplotlib\n",
    "# pip install pandas\n",
    "from glob import glob # For reading data\n",
    "import os\n",
    "import random\n",
    "import numpy as np # For storing large data in NP Arrays\n",
    "import time\n",
    "import cv2 # For image processing\n",
    "import sklearn # For machine learning\n",
    "import tensorflow as tf # For CNN\n",
    "from tensorflow import keras # For CNN\n",
    "import matplotlib.pyplot as plt # For data visualizing\n",
    "from sklearn.model_selection import train_test_split # For splitting data into training set and testing set\n",
    "from tensorflow.keras.models import Sequential # For NN\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization # For adding CNN convolution layers\n",
    "from tensorflow.keras.optimizers import Adam # For Learning Rate\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping # For saving model and stop training model earlier if needed\n",
    "from tensorflow.keras.applications import ResNet50 # For using ResNet-50 Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: The data folder is placed in the parent directory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function of loading photos as the data\n",
    "def getData():\n",
    "    real = glob(\"../data/original/*\")\n",
    "    fake_all = glob(\"../data/manipulated/*\")\n",
    "    trainX = []\n",
    "    trainY = np.hstack((np.ones(len(real), dtype=int),np.zeros(len(fake_all),dtype=int)))\n",
    "    l = len(real+fake_all)\n",
    "    for img_path in (real+fake_all):\n",
    "        trainX.append(np.array(cv2.resize(cv2.imread(img_path),(150,150))) / 255.0)\n",
    "        if(len(trainX)%(0.1*l)==0):print(f'process: {100*len(trainX)/l}%**')\n",
    "    return np.asarray(trainX), trainY\n",
    "\n",
    "# Function of generating graph for CNN performance evaluations\n",
    "def plotPerformance(hist,model,do,lr,bs):\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    plt.plot(hist.history['val_accuracy'])\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "    plt.savefig(f'pics/{model}_{do}do{lr}lr{bs}bs.png')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "By mixing the real and manipulated photos we have total 12000 photos. First divide the training and test set."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_X,all_Y = getData()\n",
    "trainX, testX, trainY, testY = train_test_split(all_X,all_Y,test_size=0.2, random_state=4487)\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setting seed for constructing the same (or at least similar) model\n",
    "os.environ['TF_CUDNN_DETERMINISTIC']= '1'\n",
    "os.environ['PYTHONHASHSEED']= '4487'\n",
    "np.random.seed(4487)\n",
    "random.seed(4487)\n",
    "tf.random.set_seed(4487)\n",
    "\n",
    "print('Initialising configs...')\n",
    "\n",
    "# do = input('Please enter the dropout rate: ')\n",
    "# lr = input('Please enter the learning rate: ')\n",
    "# epoch = input('Please enter the # of epochs: ')\n",
    "# bs = input('Please enter the # of batch size: ')\n",
    "do=0.2\n",
    "lr=3e-2\n",
    "epoch=50\n",
    "bs=64\n",
    "print('working on CNN model')\n",
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer (7x7 kernel)\n",
    "model.add(Conv2D(32, 7, activation='relu', padding='same', input_shape=(150,150,3)))\n",
    "model.add(BatchNormalization()) # Normalizing input (mean close to 0 & S. close to 1)\n",
    "\n",
    "# Second convolutional layer (5x5 kernel)\n",
    "model.add(Conv2D(32, 5, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Third convolutional layer (3x3 kernel)\n",
    "model.add(Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Forth convolutional layer (3x3 kernel)\n",
    "model.add(Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Fifth convolutional layer (3x3 kernel)\n",
    "model.add(Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling2D()) # Downsample the input\n",
    "model.add(Flatten()) # Flatten the input\n",
    "\n",
    "# Output\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dropout(float(do))) # For preventing overfitting\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the model using binary_crossentropy loss function and evalutate accuracy score\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(learning_rate=float(lr)), metrics=['accuracy'])\n",
    "\n",
    "# Early stop the program if the val_loss does not improve for 5 epochs\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 5, verbose = 0, mode = 'min', restore_best_weights=True)\n",
    "\n",
    "# Saving the best model according to val_accuracy (accuracy of testing)\n",
    "checkpoint = ModelCheckpoint(\"ConvNet.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "tf.random.set_seed(4487)\n",
    "CNN_hist=model.fit(trainX,trainY,epochs=int(epoch),batch_size=int(bs),validation_data=(testX,testY), callbacks=[checkpoint, early_stopping])\n",
    "\n",
    "# Plot the graph and save the performance\n",
    "plotPerformance(CNN_hist,model,str(do),str(lr),str(bs))\n",
    "\n",
    "# For the model outputs, some checkpoints were saved when they have obtained the best performance at that moment. We have vectorized the checkpoints and save as copies for later visualisations.\n",
    "t = np.reshape(np.hstack((np.array(CNN_hist.history['accuracy']),np.array(CNN_hist.history['val_accuracy']),np.array(CNN_hist.history['loss']),np.array(CNN_hist.history['val_loss']))),(len(CNN_hist.history['accuracy']),4),'F')\n",
    "np.save(f\"vectors/CNN_{do}do{lr}lr{bs}bs\",t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Resnet model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setting seed for constructing the same (or at least similar) model\n",
    "os.environ['TF_CUDNN_DETERMINISTIC']= '1'\n",
    "os.environ['PYTHONHASHSEED']= '4487'\n",
    "np.random.seed(4487)\n",
    "random.seed(4487)\n",
    "tf.random.set_seed(4487)\n",
    "\n",
    "print('Initialising configs...')\n",
    "model = \"RESNET\"\n",
    "# do = input('Please enter the dropout rate: ')\n",
    "# lr = input('Please enter the learning rate: ')\n",
    "# epoch = input('Please enter the # of epochs: ')\n",
    "# bs = input('Please enter the # of batch size: ')\n",
    "do=0.23\n",
    "lr=3e-4\n",
    "epoch=50\n",
    "bs=64\n",
    "ResNet_model = Sequential()\n",
    "\n",
    "# Adding ResNet50 layer\n",
    "ResNet_model.add(ResNet50(weights='imagenet', include_top=False, classes=2, input_shape=(150,150,3)))\n",
    "ResNet_model.add(BatchNormalization()) # Normalizing input (mean close to 0 & standart deviation close to 1)\n",
    "\n",
    "ResNet_model.add(MaxPooling2D()) # Downsample the input\n",
    "ResNet_model.add(Flatten()) # Flatten the input\n",
    "\n",
    "# Output\n",
    "ResNet_model.add(Dense(128, activation='relu', kernel_initializer = 'he_uniform')) # output = activation(dot(input, kernel) + bias)\n",
    "ResNet_model.add(Dropout(float(do))) # For preventing overfitting\n",
    "ResNet_model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the model using binary_crossentropy loss function and evalutate accuracy score\n",
    "ResNet_model.compile(loss='binary_crossentropy',optimizer=Adam(learning_rate=float(lr)), metrics=['accuracy'])\n",
    "\n",
    "# ResNet_model = load_model(filepath=\"ResNet.h5\", compile=True)\n",
    "# Early stop the program if the val_loss does not improve for 5 epochs\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 10, verbose = 0, mode = 'min', restore_best_weights=True)\n",
    "\n",
    "# Saving the best model according to val_accuracy (accuracy of testing)\n",
    "checkpoint = ModelCheckpoint(\"ResNet.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "tf.random.set_seed(4487)\n",
    "ResNet_hist=ResNet_model.fit(trainX,trainY,epochs=int(epoch),batch_size = int(bs),validation_data=(testX,testY), callbacks=[checkpoint, early_stopping])\n",
    "\n",
    "# Plot the graph and save the performance\n",
    "plotPerformance(ResNet_hist,model,str(do),str(lr),str(bs))\n",
    "\n",
    "# For the model outputs, some checkpoints were saved when they have obtained the best performance at that moment. We have vectorized the checkpoints and save as copies for later visualisations.\n",
    "t = np.reshape(np.hstack((np.array(ResNet_hist.history['accuracy']),np.array(ResNet_hist.history['val_accuracy']),np.array(ResNet_hist.history['loss']),np.array(ResNet_hist.history['val_loss']))),(len(ResNet_hist.history['accuracy']),4),'F')\n",
    "np.save(f\"vectors/RESNET_{do}do{lr}lr{bs}bs\",t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have decided to dig into the effects of different parameters. For both CNN and ResNet model, the hyperparameters are as below\n",
    "\n",
    "- Dropout Rate\n",
    "- Learning Rate\n",
    "- Patience of Early Stopping\n",
    "- Batch Size\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Then we could load the saved checkpoints and visualise them.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "print(f'We have saved {len(os.listdir(\"vectors/\"))} data, {len(glob(\"vectors/CNN*\"))} for CNN model and {len(glob(\"vectors/RESNET*\"))} for ResNet model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "_**Short Terms**_\n",
    "\n",
    "do -> Dropout Rate\n",
    "\n",
    "lr -> Learning Rate\n",
    "\n",
    "bs -> Batch Size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CNN Models performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CNN = glob('vectors/CNN*')\n",
    "rows = len(CNN)\n",
    "fig,axs = plt.subplots(rows, 2,figsize=(20,20))\n",
    "for row,data in enumerate(CNN):\n",
    "    title = os.path.split(data[:-4])[1]\n",
    "    d = np.load(data)\n",
    "    axs[row,0].plot(d[:,0],label='Accuracy');axs[row,0].plot(d[:,1],label='Val_acc')\n",
    "    axs[row,1].plot(d[:,2],label='Loss');axs[row,1].plot(d[:,3],label='Val_loss')\n",
    "    axs[row,0].set_title(f'{title} Accuracy');axs[row,1].set_title(f'{title} Loss')\n",
    "    axs[row,0].legend(loc='best');axs[row,1].legend(loc='best')\n",
    "plt.subplots_adjust(hspace = 0.7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We could notice that learning rate of 3e-3 has a more stable accuracy with fixed batch size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for data in CNN:\n",
    "    config = data[data.find('_')+1:][:-4]\n",
    "    d = np.load(data) # accuracy val_accuracy loss val_loss\n",
    "    plt.plot(d[:,1], label=config)\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Validation Accuracy of CNN model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for data in CNN:\n",
    "    config = data[data.find('_')+1:][:-4]\n",
    "    d = np.load(data) # accuracy val_accuracy loss val_loss\n",
    "    plt.plot(d[:,3], label=config)\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Validation Loss of CNN model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RESNET = glob('vectors/RESNET*')\n",
    "rows = len(RESNET)\n",
    "fig,axs = plt.subplots(rows, 2,figsize=(20,20))\n",
    "for row,data in enumerate(RESNET):\n",
    "    title = os.path.split(data[:-4])[1]\n",
    "    d = np.load(data)\n",
    "    axs[row,0].plot(d[:,0],label='Accuracy');axs[row,0].plot(d[:,1],label='Val_acc')\n",
    "    axs[row,1].plot(d[:,2],label='Loss');axs[row,1].plot(d[:,3],label='Val_loss')\n",
    "    axs[row,0].set_title(f'{title} Accuracy');axs[row,1].set_title(f'{title} Loss')\n",
    "    axs[row,0].legend(loc='best');axs[row,1].legend(loc='best')\n",
    "plt.subplots_adjust(hspace = 0.7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for data in RESNET:\n",
    "    config = data[data.find('_')+1:][:-4]\n",
    "    d = np.load(data) # accuracy val_accuracy loss val_loss\n",
    "    plt.plot(d[:,1], label=config)\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Validation Accuracy of ResNet model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We could see that the lowest learning rate have the largest validation accuracy compared with a higher value in learning rate."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for data in RESNET:\n",
    "    config = data[data.find('_') + 1:][:-4]\n",
    "    d = np.load(data)  # accuracy val_accuracy loss val_loss\n",
    "    plt.plot(d[:, 3], label=config)\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Validation Loss of ResNet model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "removed_outlier = RESNET.copy()\n",
    "removed_outlier.remove('vectors/RESNET_0.2do3e-3lr64bs.npy')\n",
    "for data in removed_outlier:\n",
    "    config = data[data.find('_') + 1:][:-4]\n",
    "    d = np.load(data)  # accuracy val_accuracy loss val_loss\n",
    "    plt.plot(d[:, 3], label=config)\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Validation Loss of ResNet model - without the outlier')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Section 3 - Challenges"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reproducing models with the same result\n",
    "\n",
    "Since this project can only be handed in an ipynb file, we cannot upload the finished model directly. However, every time we run Keras, splitting the data set and the weighting inside the models differ. Thus, the result is inconsistent. As a result, we tried to figure out methods to reproduce the same or as similar as we could. We initially tried using the checkpoint callback to save and load the model. This function allows us to load the previously saved weights to re-evaluate or continue the existing model's training process. For instance, if the model stops training at epoch 5, we may load the same model and resume training again. For exmaple\n",
    "\n",
    "- ### ResNet_model = load_model(filepath=\"ResNet.h5\", compile=True)\n",
    "\n",
    "However, we found that this method does not meet our goal since it still requires a model file to be loaded."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading the same seeds\n",
    "We then installed the package TensorFlow-determinism and make sure the seed of NumPy, python_random and TensorFlow were the same. Most of the time we gain same values for the val_accuracy and a little bit varies for the loss."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GPU server\n",
    "\n",
    "**packages conflict** During the package installation, since some versions of different packages are in conflict, it results in uninstallation of some sub-packages is required. Since TensorFlow is a large package in which some of its sub-packages are not compatible with the other packages in different versions. We wasted lots of time troubleshooting the package version problem even if the program can be run successfully on other devices or even on the same computer using CPU.\n",
    "\n",
    "**Memory Limitations** It seems that there are limitations for memory usage every day for each account. In the beginning, we kept importing the full dataset for training models with different parameters and testing re-producing the same model until the out-of-memory error appeared. We then separate a small dataset with only 120 images (40 real, 80 fake) and reduce the number of epochs for testing.\n",
    "\n",
    "<img src=\"p/Memory.jpeg\" width=\"1600\" height=\"372\">\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'[memory]' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}